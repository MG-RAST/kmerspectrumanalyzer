#!/usr/bin/env python

"""Script to use jellyfish to get kmer information
Input: fasta/fastq file
Output: kmer information, one of:
  1. hash: binary hash of counts
  2. stats: summary stats
  3. dump: profile (kmer seq - count)
  4. histo: histogram (count - abundance)
  5. histo ranked:  columns 1: count 2:abundance 3:count*abundance
       4: reverse-sum(abundance) 5: reverse-sum(count*abundance) 
       6: ratio-to-largest
"""

import sys, os, glob, string, random
import itertools, subprocess
import argparse
GB = 1073741824
BUFFER = 2 * GB     # 2 Gb seq buffer
TYPES = ['fasta', 'fastq', 'hash']
FORMATS = ['hash', 'stats', 'dump', 'histo']

def run_cmd(cmd):
    '''Wrapper for Popen, returns stdout, stderr'''
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    if proc.returncode != 0:
        raise IOError("%s\n%s" % (" ".join(cmd), stderr))
    return stdout, stderr

def random_str(size=6):
    '''Retruns random alphanumeric sequence for temporary filenames.'''
    chars = string.ascii_letters + string.digits
    return ''.join(random.choice(chars) for x in range(size))

def split_fasta(in_fh, file_base, max_size):
    '''Splits fasta file into files of approx max_size bytes.
    Returns array of filenames of the parts'''
    curr_size = 0
    curr_buff = 0
    curr_file = 0
    strbuffer = ''
    firstline = 1
    fhdl_name = ["%s.%d" % (file_base, curr_file + 1)]
    fhdl_set = [open(fhdl_name[curr_file], "w")]
    for line in in_fh:
        if firstline:
            assert line[0] == ">", "Wrong data type! Error splitting FASTA"
            firstline = 0
        head = line[0] == ">"
        if head and ((curr_size + curr_buff) >= max_size):
            fhdl_set[curr_file].write(strbuffer)
            curr_size = 0
            curr_buff = 0
            curr_file += 1
            fhdl_name.append("%s.%d" % (file_base, curr_file + 1))
            fhdl_set.append(open(fhdl_name[curr_file], "w"))
            strbuffer = ''
        if head and (curr_buff > BUFFER):
            fhdl_set[curr_file].write(strbuffer)
            curr_size += curr_buff
            curr_buff = 0
            strbuffer = ''
        strbuffer += line
        curr_buff += len(line)
    if strbuffer != '':
        fhdl_set[curr_file].write(strbuffer)
    for fh in fhdl_set:
        fh.close()
    return fhdl_name

def split_fastq(in_fh, file_base, max_size):
    '''Splits fastq file into files of approx max_size bytes.'''
    curr_size = 0
    curr_buff = 0
    curr_file = 0
    strbuffer = ''
    firstline = 1
    fhdl_name = ["%s.%d" % (file_base, curr_file + 1)]
    fhdl_set = [open(fhdl_name[curr_file], "w")]
    f = in_fh
    if True:
        for lines in itertools.izip_longest(*[f]*4):
            if firstline == 1:
                assert lines[0][0] == "@", "Wrong data type!  Error splitting FASTQ!"
                firstline = 0
            if (curr_size + curr_buff) >= max_size:
                fhdl_set[curr_file].write(strbuffer)
                curr_size = 0
                curr_buff = 0
                curr_file += 1
                fhdl_name.append("%s.%d" % (file_base, curr_file + 1))
                fhdl_set.append(open(fhdl_name[curr_file], "w"))
                strbuffer = ''
            if curr_buff > BUFFER:
                fhdl_set[curr_file].write(strbuffer)
                curr_size += curr_buff
                curr_buff = 0
                strbuffer = ''
            rec_str = ''.join(lines)
            strbuffer += rec_str
            curr_buff += len(rec_str)
    if strbuffer != '':
        fhdl_set[curr_file].write(strbuffer)
    for fh in fhdl_set:
        fh.close()
    return fhdl_name

def split_seq_file(seq_fh, max_size, seq_type, tmpdir):
    '''splits sequence file by calling split_fasta or split_fastq.
    Returns list of filenames resulting from the split.'''
    file_base = os.path.join(tmpdir, "%s.%s" % (random_str(), seq_type))
    if seq_type == 'fasta':
        file_set = split_fasta(seq_fh, file_base, max_size)
    elif seq_type == 'fastq':
        file_set = split_fastq(seq_fh, file_base, max_size)
    return file_set

def merge_hash_set(hash_set, tmpdir):
    ''' Runs jellyfish merge on a list of hash files.  Returns a filename
    containing the merged data.'''
    if len(hash_set) == 1:
        return hash_set[0]
    merge_file = os.path.join(tmpdir, random_str() + '.js')
    merge_cmd = ['jellyfish', 'merge', '-o', merge_file]
    merge_cmd.extend(hash_set)
    _sout, _serr = run_cmd(merge_cmd)
    for h in hash_set:
        os.remove(h)
    if not os.path.isfile(merge_file):
        sys.stderr.write("[error] jellyfish count returned no results")
        sys.stderr.write(_serr)
        sys.exit(0)
    return merge_file

def ranked_histo(data_str):
    sum_col_1 = 0
    sum_col_2 = 0
    data_matrix = []
    for rrow in reversed(data_str.strip().split("\n")):
        num, count = rrow.strip().split()
        product_0_1 = int(num) * int(count)
        sum_col_1 += int(count)
        sum_col_2 += product_0_1
        data_matrix.append([num, count, product_0_1, sum_col_1, sum_col_2])
    for i in range(len(data_matrix)):
        ratio = data_matrix[i][4] * 1.0 / sum_col_2
        data_matrix[i].append("%.4f" % ratio)
    data_matrix.reverse()
    return data_matrix

def kmer_count(infile, procs, length, size, count, tmpdir):
    '''
    Arguments infile, procs, length, size, count, tmpdir
    returns filename of merged kmer hashes'''
    jf_base = os.path.join(tmpdir, random_str() + '.js.part')
    jf_cmd = ['jellyfish', 'count', '-C', '-t', str(procs), '-m', str(length), 
        '-c', str(count), '-s', size, '-o', jf_base, infile]
    _sout, _serr = run_cmd(jf_cmd)
    parts = glob.glob(jf_base + '_*')
    return merge_hash_set(parts, tmpdir)

def main(args):
    usage = "usage: kmer-tool [options] -i <input file> -o <output file>"
    parser = argparse.ArgumentParser(description=usage)
    parser.add_argument("-i", "--input", dest="input", default="-", type=argparse.FileType("r"), help="Input file, sequence (fasta/fastq) or binary count hash.")
    parser.add_argument("-o", "--output", dest="output", default=None, type=argparse.FileType('w'), help="Output file.")
    parser.add_argument("-t", "--type", dest="type", default='fasta', help="Input file type, one of: %s [default 'fasta']" % (", ".join(TYPES)))
    parser.add_argument("-m", "--max", dest="max", default=10.0, type=float, help="Maximum size (in Gb) to count, files larger are split [default 10.0].")
    parser.add_argument("-p", "--procs", dest="procs", default=4, type=int, help="Number of processors to use [default 4].")
    parser.add_argument("-l", "--length", dest="length", default=None, type=int, help="Length of kmer to use.")
    parser.add_argument("-s", "--size", dest="size", default="1000000000", help="Size of hash to use, number of unique kmers [default '1G']")
    parser.add_argument("-c", "--count", dest="count", default=12, type=int, help="Count size in bits [default '12']")
    parser.add_argument("-f", "--format", dest="format", default='histo', help="Output format, one of: %s [default 'histo']" % (", ".join(FORMATS)))
    parser.add_argument("--histo_max", dest="histo_max", default=10000000, type=int, help="Max count value for histogram [default 10000000]")
    parser.add_argument("-r", "--ranked", dest="ranked", action="store_true", default=False, help="histo output includes additional transformations for ranked plot")
    parser.add_argument("-d", "--tmpdir", dest="tmpdir", default=None, help="Dir to store intermediate files [default is dir of output file]")

    args = parser.parse_args()
    if sys.version_info < (2,6):
        raise Exception("Python version 2.6 or later is required for kmer-tool2")
    if args.output == None:
        parser.error("[error] missing output files")
    if not args.type in TYPES:
        parser.error("[error] missing input type, use one of: %s" % (", ".join(TYPES)))
    if not args.format in FORMATS:
        parser.error("[error] missing output format, use one of: %s" %(", ".join(FORMATS)))
    if (args.type != 'hash') and (not args.length or (args.length < 2)):
        parser.error("[error] missing / invalid kmer length")
    if (args.type == 'hash') and (args.format == 'hash'):
        parser.error("[error] both input and output is binary hash")


    if args.procs < 1:
        args.procs = 1
    if args.count < 2:
        args.count = 2
    if not args.tmpdir:
        args.tmpdir = os.path.dirname(args.output.name)

    # get kmer count hash
    if args.type == 'hash':
        jf_hash = args.input
    else:
        # check file size, split if too large
        max_size = args.max * GB
        if args.input is sys.stdin:
            input_set = split_seq_file(args.input, max_size, args.type, args.tmpdir)
        else:
            # If file is small enough, bypass splitting
            if  os.fstat(args.input.fileno()).st_size < max_size:   
                args.input.close()
                input_set = [args.input.name]
            else:
                input_set = split_seq_file(args.input, max_size, args.type, args.tmpdir)

        # get hash set
        hash_set = []
        for ifile in input_set:
            if (os.path.getsize(ifile) > 0) and os.path.isfile(ifile):
                hash_set.append(kmer_count(ifile, args.procs, args.length,
                     args.size, args.count, args.tmpdir))
        jf_hash = merge_hash_set(hash_set, args.tmpdir)
        # cleanup
        if len(input_set) > 1:
            for f in input_set:
                os.remove(f)
        if args.format == 'hash':
            args.output.close()
            os.rename(jf_hash, args.output.name)
            return 0

    output_cmd = ['jellyfish', args.format]
    if args.format == 'histo':
        output_cmd.extend(['-t', str(args.procs), '-h', str(args.histo_max)])
    elif args.format == 'dump':
        output_cmd.extend(['-c', '-t'])
    output_cmd.append(jf_hash)
    sout, serr = run_cmd(output_cmd)

    ohdl = args.output
    if args.ranked:
        extra_data = ranked_histo(sout)
        for row in extra_data:
            line = "\t".join(map(lambda x: str(x), row)) + "\n"
            ohdl.write(line)
    else:
        ohdl.write(sout)
    ohdl.close()

    if args.type != 'hash':
        os.remove(jf_hash)
#      if not os.path.isfile(args.output):
#          sys.stderr.write("[error] jellyfish %s returned no results"%(args.format))
#          sys.stderr.write(serr)
#          return 1

    return 0

if __name__ == "__main__":
    sys.exit(main(sys.argv))
